{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a104e9c-09dc-44e4-9746-999186050c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pyspark project.spark.fine-grained\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "import org.apache.spark.sql.functions._\n",
    "import com.amazonaws.services.glue.GlueContext\n",
    "import org.apache.spark.SparkContext\n",
    "\n",
    "object KinesisToIcebergStreaming {\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    // Initialize Spark Session with Iceberg support\n",
    "    val spark = SparkSession.builder()\n",
    "      .appName(\"Kinesis-To-Iceberg-Streaming\")\n",
    "      .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "      .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "      .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\")\n",
    "      .config(\"spark.sql.catalog.aws_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "      .config(\"spark.sql.catalog.aws_catalog.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\")\n",
    "      .config(\"spark.sql.catalog.aws_catalog.warehouse\", \"s3://your-bucket/warehouse/\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    // Read from Kinesis Data Stream\n",
    "    val streamingDF = spark.readStream\n",
    "      .format(\"kinesis\")\n",
    "      .option(\"streamName\", \"your-stream-name\")\n",
    "      .option(\"endpointUrl\", \"https://kinesis.your-region.amazonaws.com\")\n",
    "      .option(\"startingPosition\", \"TRIM_HORIZON\") // or LATEST\n",
    "      .option(\"awsSTSRoleARN\", \"arn:aws:iam::account:role/role-name\") // if using role-based auth\n",
    "      .load()\n",
    "\n",
    "    // Assuming the data is in JSON format, parse it\n",
    "    // Modify this according to your data structure\n",
    "    val parsedDF = streamingDF\n",
    "      .selectExpr(\"cast (data as STRING) as json_data\")\n",
    "      .select(from_json(col(\"json_data\"), \n",
    "        // Define your schema here\n",
    "        \"struct<id:string, timestamp:timestamp, value:double>\"\n",
    "      ).as(\"data\"))\n",
    "      .select(\"data.*\")\n",
    "\n",
    "    // Write to Iceberg table\n",
    "    val query = parsedDF.writeStream\n",
    "      .format(\"iceberg\")\n",
    "      .outputMode(\"append\")\n",
    "      .option(\"path\", \"aws_catalog.your_database.your_table\")\n",
    "      .option(\"checkpointLocation\", \"s3://your-bucket/checkpoints/\")\n",
    "      .trigger(Trigger.ProcessingTime(\"1 minute\"))\n",
    "      .start()\n",
    "\n",
    "    query.awaitTermination()\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
